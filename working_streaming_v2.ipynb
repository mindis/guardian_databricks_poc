{"cells":[{"cell_type":"code","source":["dbutils.library.installPyPI(\"mlflow\")\ndbutils.library.restartPython()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"18eb2669-5764-436a-840c-04aff546d57c"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["from pyspark.sql.types import StructType\nfrom pyspark.sql.types import *\nfrom pyspark.sql import SparkSession\nfrom pyspark.sql.types import StructType\nfrom pyspark.sql.functions import *      # for window() function\nfrom typing import List\nfrom pyspark.sql.types import *\nimport pandas as pd\nimport time\nfrom datetime import datetime, timedelta, timezone\nimport mlflow\nfrom pyspark.sql.types import StructType"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"7ee863e6-9acd-4796-80b7-8f150f868b10"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["%sql\nDROP TABLE raw_log_data_delta_PN;\nDROP TABLE anomalies_data_delta_PN_;"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"3f2638fe-1e67-4177-882f-de18317332cf"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"overflow":false,"datasetInfos":[],"data":[],"plotOptions":{"displayType":"table","customPlotOptions":{},"pivotColumns":null,"pivotAggregation":null,"xColumns":null,"yColumns":null},"columnCustomDisplayInfos":{},"aggType":"","isJsonSchema":true,"removedWidgets":[],"aggSchema":[],"schema":[],"aggError":"","aggData":[],"addedWidgets":{},"dbfsResultPath":null,"type":"table","aggOverflow":false,"aggSeriesLimitReached":false,"arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr></tr></thead><tbody></tbody></table></div>"]}}],"execution_count":0},{"cell_type":"code","source":["%sql\nCREATE TABLE raw_log_data_delta_PN (\n  account_id STRING,\n  agent_id STRING,\n  event STRING,\n  timestamp TIMESTAMP\n )\nUSING DELTA;\n\n\nCREATE TABLE anomalies_data_delta_PN_ (\n  user_id string,\n  Ips LONG,\n  prediction DOUBLE\n)\nUSING DELTA;\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"Creating Required tables","showTitle":true,"inputWidgets":{},"nuid":"8ee54bd0-91a2-401b-8fdb-7c2b2068527e"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"overflow":false,"datasetInfos":[],"data":[],"plotOptions":{"displayType":"table","customPlotOptions":{},"pivotColumns":null,"pivotAggregation":null,"xColumns":null,"yColumns":null},"columnCustomDisplayInfos":{},"aggType":"","isJsonSchema":true,"removedWidgets":[],"aggSchema":[],"schema":[],"aggError":"","aggData":[],"addedWidgets":{},"dbfsResultPath":null,"type":"table","aggOverflow":false,"aggSeriesLimitReached":false,"arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr></tr></thead><tbody></tbody></table></div>"]}}],"execution_count":0},{"cell_type":"code","source":["inputPath = \"dbfs:/mnt/kafka_raw/57c7413abca837e974000009/\"\n\nschema_raw_logs = (  StructType()\n  .add(\"account_id\",\"string\")\n  .add(\"agent_id\",\"string\")\n  .add(\"event\",\"string\")\n  .add(\"timestamp\",\"timestamp\") \n)\n\n\n#reads From S3\neventsDF = (\n  spark\n    .readStream\n    .schema(schema_raw_logs) # Set the schema of the JSON data\n    .option(\"maxFilesPerTrigger\", 1) # Treat a sequence of files as a stream by picking one file at a time\n    .json(inputPath)\n)\n\n#writes to Raw table\n(eventsDF.writeStream\n  .outputMode(\"append\")\n  .option(\"checkpointLocation\", \"/mnt/delta/events/_checkpoints/etl-from-json_PN_v0.16\")\n  .table(\"raw_log_data_delta_PN\")\n)\n\n\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"Streaming from S3 into a delta table","showTitle":true,"inputWidgets":{},"nuid":"3f908ea6-7b3f-48f6-bfd2-8dbd5eb9c419"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[{"name":"eventsDF","typeStr":"pyspark.sql.dataframe.DataFrame","schema":{"fields":[{"metadata":{},"name":"account_id","nullable":true,"type":"string"},{"metadata":{},"name":"agent_id","nullable":true,"type":"string"},{"metadata":{},"name":"event","nullable":true,"type":"string"},{"metadata":{},"name":"timestamp","nullable":true,"type":"timestamp"}],"type":"struct"},"tableIdentifier":null}],"data":"<div class=\"ansiout\">Out[18]: &lt;pyspark.sql.streaming.StreamingQuery at 0x7f9d39876a50&gt;</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[18]: &lt;pyspark.sql.streaming.StreamingQuery at 0x7f9d39876a50&gt;</div>"]}}],"execution_count":0},{"cell_type":"code","source":["#We may need to user OPTIMIZE, which deals with small files, merge them and compact them into larger files\nraw_data = spark.readStream.format(\"delta\").table(\"raw_log_data_delta_PN\")\n\n\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"8675f94e-e2a8-47de-8d3e-915efa6ac9a1"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[{"name":"raw_data","typeStr":"pyspark.sql.dataframe.DataFrame","schema":{"fields":[{"metadata":{},"name":"account_id","nullable":true,"type":"string"},{"metadata":{},"name":"agent_id","nullable":true,"type":"string"},{"metadata":{},"name":"event","nullable":true,"type":"string"},{"metadata":{},"name":"timestamp","nullable":true,"type":"timestamp"}],"type":"struct"},"tableIdentifier":"dbfs:/user/hive/warehouse/raw_log_data_delta_pn"}],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["fullschema = (  StructType()\n  .add(\"logger_event_id\", \"string\")\n  .add(\"logger_timestamp\",\"timestamp\")                \n  .add(\"account_id\",\"string\")\n  .add(\"agent_id\",\"string\")\n  .add(\"event\",StructType())\n         .add(\"actor\",StructType()\n             .add(\"user_id\",\"string\")\n             .add(\"ip_addresses\",ArrayType(StringType()))\n             .add(\"session_id\",\"string\")\n             .add(\"impersonated_user_id\",\"string\")\n             .add(\"id\",\"string\")\n             .add(\"type\",\"string\")\n             .add(\"user_agent\",\"string\")\n         )\n         .add(\"account_id\",\"string\")\n         .add(\"event_type\",\"string\")\n         .add(\"audit\",StructType()\n              .add(\"severity\",\"string\")\n              .add(\"resource_id\",\"string\")\n              .add(\"operation\",\"string\")\n              .add(\"timestamp\",\"timestamp\")\n              .add(\"status\",\"string\")\n         )\n         .add(\"logger_event_id\",\"string\")     \n         .add(\"object\",StructType())\n         .add(\"timestamp\",\"timestamp\") \n   \n   .add(\"timestamp\",\"timestamp\") \n)\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"fa449ed0-7baa-4d26-8699-06365ef025b2"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["run_id = \"09840597c6e04f279aaa27be313c6e73\"\nmodel_uri = \"runs:/\" + run_id + \"/sklearn-model\"\n\n#model = mlflow.pyfunc.spark_udf(spark, model_uri)\nmodel = mlflow.spark.load_model(model_uri)\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"69d44ca1-0c50-4d80-a2af-472b04e5b940"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">2020/10/06 15:32:16 INFO mlflow.spark: &#39;runs:/09840597c6e04f279aaa27be313c6e73/sklearn-model&#39; resolved as &#39;dbfs:/databricks/mlflow/3045381443611622/09840597c6e04f279aaa27be313c6e73/artifacts/sklearn-model&#39;\n</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">2020/10/06 15:32:16 INFO mlflow.spark: &#39;runs:/09840597c6e04f279aaa27be313c6e73/sklearn-model&#39; resolved as &#39;dbfs:/databricks/mlflow/3045381443611622/09840597c6e04f279aaa27be313c6e73/artifacts/sklearn-model&#39;\n</div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"type":"ipynbError","data":"<div class=\"ansiout\"><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n<span class=\"ansi-red-fg\">MlflowException</span>                           Traceback (most recent call last)\n<span class=\"ansi-green-fg\">&lt;command-1977472393598320&gt;</span> in <span class=\"ansi-cyan-fg\">&lt;module&gt;</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      3</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">      4</span> <span class=\"ansi-red-fg\">#model = mlflow.pyfunc.spark_udf(spark, model_uri)</span>\n<span class=\"ansi-green-fg\">----&gt; 5</span><span class=\"ansi-red-fg\"> </span>model <span class=\"ansi-blue-fg\">=</span> mlflow<span class=\"ansi-blue-fg\">.</span>spark<span class=\"ansi-blue-fg\">.</span>load_model<span class=\"ansi-blue-fg\">(</span>model_uri<span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-green-fg\">/local_disk0/pythonVirtualEnvDirs/virtualEnv-c507b5d6-cdc8-49c1-831f-521c88942aae/lib/python3.7/site-packages/mlflow/spark.py</span> in <span class=\"ansi-cyan-fg\">load_model</span><span class=\"ansi-blue-fg\">(model_uri, dfs_tmpdir)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    558</span>         model_uri <span class=\"ansi-blue-fg\">=</span> ModelsArtifactRepository<span class=\"ansi-blue-fg\">.</span>get_underlying_uri<span class=\"ansi-blue-fg\">(</span>model_uri<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    559</span>         _logger<span class=\"ansi-blue-fg\">.</span>info<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#34;&#39;%s&#39; resolved as &#39;%s&#39;&#34;</span><span class=\"ansi-blue-fg\">,</span> runs_uri<span class=\"ansi-blue-fg\">,</span> model_uri<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-fg\">--&gt; 560</span><span class=\"ansi-red-fg\">     </span>flavor_conf <span class=\"ansi-blue-fg\">=</span> _get_flavor_configuration_from_uri<span class=\"ansi-blue-fg\">(</span>model_uri<span class=\"ansi-blue-fg\">,</span> FLAVOR_NAME<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    561</span>     model_uri <span class=\"ansi-blue-fg\">=</span> append_to_uri_path<span class=\"ansi-blue-fg\">(</span>model_uri<span class=\"ansi-blue-fg\">,</span> flavor_conf<span class=\"ansi-blue-fg\">[</span><span class=\"ansi-blue-fg\">&#34;model_data&#34;</span><span class=\"ansi-blue-fg\">]</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    562</span>     <span class=\"ansi-green-fg\">return</span> _load_model<span class=\"ansi-blue-fg\">(</span>model_uri<span class=\"ansi-blue-fg\">=</span>model_uri<span class=\"ansi-blue-fg\">,</span> dfs_tmpdir<span class=\"ansi-blue-fg\">=</span>dfs_tmpdir<span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-green-fg\">/local_disk0/pythonVirtualEnvDirs/virtualEnv-c507b5d6-cdc8-49c1-831f-521c88942aae/lib/python3.7/site-packages/mlflow/utils/model_utils.py</span> in <span class=\"ansi-cyan-fg\">_get_flavor_configuration_from_uri</span><span class=\"ansi-blue-fg\">(model_uri, flavor_name)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     65</span>         raise MlflowException(\n<span class=\"ansi-green-intense-fg ansi-bold\">     66</span>             <span class=\"ansi-blue-fg\">&#39;Model does not have the &#34;{flavor_name}&#34; flavor&#39;</span><span class=\"ansi-blue-fg\">.</span>format<span class=\"ansi-blue-fg\">(</span>flavor_name<span class=\"ansi-blue-fg\">=</span>flavor_name<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">,</span>\n<span class=\"ansi-green-fg\">---&gt; 67</span><span class=\"ansi-red-fg\">             </span>RESOURCE_DOES_NOT_EXIST<span class=\"ansi-blue-fg\">,</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     68</span>         )\n<span class=\"ansi-green-intense-fg ansi-bold\">     69</span>     <span class=\"ansi-green-fg\">return</span> model_conf<span class=\"ansi-blue-fg\">.</span>flavors<span class=\"ansi-blue-fg\">[</span>flavor_name<span class=\"ansi-blue-fg\">]</span>\n\n<span class=\"ansi-red-fg\">MlflowException</span>: Model does not have the &#34;spark&#34; flavor</div>","errorSummary":"<span class=\"ansi-red-fg\">MlflowException</span>: Model does not have the &#34;spark&#34; flavor","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n<span class=\"ansi-red-fg\">MlflowException</span>                           Traceback (most recent call last)\n<span class=\"ansi-green-fg\">&lt;command-1977472393598320&gt;</span> in <span class=\"ansi-cyan-fg\">&lt;module&gt;</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      3</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">      4</span> <span class=\"ansi-red-fg\">#model = mlflow.pyfunc.spark_udf(spark, model_uri)</span>\n<span class=\"ansi-green-fg\">----&gt; 5</span><span class=\"ansi-red-fg\"> </span>model <span class=\"ansi-blue-fg\">=</span> mlflow<span class=\"ansi-blue-fg\">.</span>spark<span class=\"ansi-blue-fg\">.</span>load_model<span class=\"ansi-blue-fg\">(</span>model_uri<span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-green-fg\">/local_disk0/pythonVirtualEnvDirs/virtualEnv-c507b5d6-cdc8-49c1-831f-521c88942aae/lib/python3.7/site-packages/mlflow/spark.py</span> in <span class=\"ansi-cyan-fg\">load_model</span><span class=\"ansi-blue-fg\">(model_uri, dfs_tmpdir)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    558</span>         model_uri <span class=\"ansi-blue-fg\">=</span> ModelsArtifactRepository<span class=\"ansi-blue-fg\">.</span>get_underlying_uri<span class=\"ansi-blue-fg\">(</span>model_uri<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    559</span>         _logger<span class=\"ansi-blue-fg\">.</span>info<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#34;&#39;%s&#39; resolved as &#39;%s&#39;&#34;</span><span class=\"ansi-blue-fg\">,</span> runs_uri<span class=\"ansi-blue-fg\">,</span> model_uri<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-fg\">--&gt; 560</span><span class=\"ansi-red-fg\">     </span>flavor_conf <span class=\"ansi-blue-fg\">=</span> _get_flavor_configuration_from_uri<span class=\"ansi-blue-fg\">(</span>model_uri<span class=\"ansi-blue-fg\">,</span> FLAVOR_NAME<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    561</span>     model_uri <span class=\"ansi-blue-fg\">=</span> append_to_uri_path<span class=\"ansi-blue-fg\">(</span>model_uri<span class=\"ansi-blue-fg\">,</span> flavor_conf<span class=\"ansi-blue-fg\">[</span><span class=\"ansi-blue-fg\">&#34;model_data&#34;</span><span class=\"ansi-blue-fg\">]</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    562</span>     <span class=\"ansi-green-fg\">return</span> _load_model<span class=\"ansi-blue-fg\">(</span>model_uri<span class=\"ansi-blue-fg\">=</span>model_uri<span class=\"ansi-blue-fg\">,</span> dfs_tmpdir<span class=\"ansi-blue-fg\">=</span>dfs_tmpdir<span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-green-fg\">/local_disk0/pythonVirtualEnvDirs/virtualEnv-c507b5d6-cdc8-49c1-831f-521c88942aae/lib/python3.7/site-packages/mlflow/utils/model_utils.py</span> in <span class=\"ansi-cyan-fg\">_get_flavor_configuration_from_uri</span><span class=\"ansi-blue-fg\">(model_uri, flavor_name)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     65</span>         raise MlflowException(\n<span class=\"ansi-green-intense-fg ansi-bold\">     66</span>             <span class=\"ansi-blue-fg\">&#39;Model does not have the &#34;{flavor_name}&#34; flavor&#39;</span><span class=\"ansi-blue-fg\">.</span>format<span class=\"ansi-blue-fg\">(</span>flavor_name<span class=\"ansi-blue-fg\">=</span>flavor_name<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">,</span>\n<span class=\"ansi-green-fg\">---&gt; 67</span><span class=\"ansi-red-fg\">             </span>RESOURCE_DOES_NOT_EXIST<span class=\"ansi-blue-fg\">,</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     68</span>         )\n<span class=\"ansi-green-intense-fg ansi-bold\">     69</span>     <span class=\"ansi-green-fg\">return</span> model_conf<span class=\"ansi-blue-fg\">.</span>flavors<span class=\"ansi-blue-fg\">[</span>flavor_name<span class=\"ansi-blue-fg\">]</span>\n\n<span class=\"ansi-red-fg\">MlflowException</span>: Model does not have the &#34;spark&#34; flavor</div>"]}}],"execution_count":0},{"cell_type":"code","source":["\n\n\ndef foreach_batch_function(df, epoch_id):\n    # You can put all your query codes here. \n    # You can read from your event raw table direcctly from here and do aggregation\n    # In this example, raw_table_df is from the raw table, and you can aggregate or do any transformation you need on this based on your stream input\n\n    \n    #filter for the last 24h data\n   # agg_df = raw_data.filter(\n   #                               raw_data.timestamp <= \n   #                               datetime.strptime(str(datetime.now().astimezone(timezone.utc)\n   #                               .strftime(\"%Y-%m-%dT%H:%M:%S.%f\"))[:-3] ,\"%Y-%m-%dT%H:%M:%S.%f\") - timedelta(hours=24)\n   #                             )\n    \n    #Parse Json\n   # agg_df = raw_data.select(\"timestamp\",from_json(\"event\", fullschema).alias(\"data\"))\n    \n    \n    \n    #selecting required columns only\n   # agg_df = raw_data.select(\"timestamp\",\"data.actor.user_id\",\"data.actor.ip_addresses\")\n    \n    #filter for null user_ids\n   # agg_df = raw_data.filter(raw_table_df.user_id != None)\n    \n    \n    result = (model\n          .transform(agg_df)\n          .groupBy(\"user_id\", \"ip_addresses\")\n          .count()\n          .withColumn(\"prediction\", udf('Ips'))\n          .sort(\"user_id\", \"prediction\")\n             )\n  \n  \n    result.write.format(\"delta\").mode(\"append\").table(\"anomalies_data_delta_PN_\")\n    \n\n  \n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"5cce6fb8-0ac9-40db-9efe-a7424a6291a6"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["#query, apply foreach and write to table\nquery = (raw_data.writeStream \n        .foreachBatch(foreach_batch_function) \n        .option(\"checkpointLocation\", \"/mnt/delta/events/_checkpoints/anomalies_v.7\")\n        .start()\n      )\n   \n  "],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"2b67fd3e-a687-4e49-82bf-5f6539a0fccc"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"working_streaming_v2","dashboards":[],"language":"python","widgets":{},"notebookOrigID":1977472393598307}},"nbformat":4,"nbformat_minor":0}
